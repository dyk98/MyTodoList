# 场景配置自优化系统技术方案

## 一、概述

### 1.1 目标

构建一个支持 **自提问 → 自执行 → 自归因 → 自优化** 闭环的场景配置优化系统，同时支持 human-in-the-loop 介入。

### 1.2 核心能力

| 能力 | 说明 |
|------|------|
| 自提问 | AI 生成评测集，支持从零生成或基于人工种子集二次创作 |
| 自执行 | 基于评测集自动执行场景，收集 actual_output |
| 自归因 | AI 分析 badcase，定位失败原因到具体配置字段 |
| 自优化 | AI 生成优化后的场景配置，并说明改动原因 |
| Human-in-loop | 支持人工审核、修改评测集、确认优化 |

### 1.3 优化边界

本方案优化的场景配置字段：

| 字段 | 是否支持优化 | 说明 |
|------|-------------|------|
| `personality` | ✅ | 角色人设描述 |
| `goals` | ✅ | 核心目标描述 |
| `knowledge` | ✅ | 领域知识注入 |
| `userContext` | ✅ | 模拟对话历史 |
| `tools` | ❌ (Phase 2) | 工具配置复杂，后续支持 |
| `modelConfig` | ❌ | 模型配置由人工管理 |

---

## 二、整体架构

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           Scene Optimizer System                             │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  ┌──────────────┐    ┌──────────────┐    ┌──────────────┐    ┌────────────┐ │
│  │   评测集     │───▶│   执行引擎   │───▶│   归因引擎   │───▶│  优化引擎  │ │
│  │  Generator   │    │   Executor   │    │  Attributor  │    │  Optimizer │ │
│  └──────────────┘    └──────────────┘    └──────────────┘    └────────────┘ │
│         │                   │                   │                   │        │
│         ▼                   ▼                   ▼                   ▼        │
│  ┌──────────────────────────────────────────────────────────────────────┐   │
│  │                        数据存储层 (JSON Files)                        │   │
│  │  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐ ┌─────────────────┐ │   │
│  │  │ 评测目标    │ │ 评测集      │ │ 执行记录    │ │ 场景配置版本   │ │   │
│  │  │ EvalTarget  │ │ EvalDataset │ │ EvalResult  │ │ SceneVersion   │ │   │
│  │  └─────────────┘ └─────────────┘ └─────────────┘ └─────────────────┘ │   │
│  └──────────────────────────────────────────────────────────────────────┘   │
│         │                   │                   │                   │        │
│         ▼                   ▼                   ▼                   ▼        │
│  ┌──────────────────────────────────────────────────────────────────────┐   │
│  │                      角色扮演配置 (RolePersona)                        │   │
│  │  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐ ┌─────────────────┐ │   │
│  │  │ 6岁初学者   │ │ 12岁进阶者  │ │ 捣蛋学生    │ │ 自定义角色...   │ │   │
│  │  └─────────────┘ └─────────────┘ └─────────────┘ └─────────────────┘ │   │
│  └──────────────────────────────────────────────────────────────────────┘   │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
                                      │
                                      ▼
                    ┌─────────────────────────────────┐
                    │         Existing Driver         │
                    │   (AgentAdapter + SceneRunner)  │
                    └─────────────────────────────────┘
```

---

## 三、核心数据结构

### 3.1 角色扮演配置 (RolePersona)

```typescript
// config/eval/rolePersonas.json
interface RolePersona {
  id: string;                    // 唯一标识，如 "beginner_6yo"
  name: string;                  // 显示名称，如 "6岁初学者"
  personality: string;           // 角色人设描述
  characteristics: string[];     // 行为特征列表
  typicalInputPatterns: string[]; // 典型输入模式示例
}

// 示例
{
  "id": "beginner_6yo",
  "name": "6岁初学者",
  "personality": "你是一个6岁的小学生，刚开始学习编程，对很多概念不理解，会问很多'为什么'，容易分心，需要鼓励才能继续。",
  "characteristics": [
    "词汇量有限，使用简单句子",
    "注意力容易分散",
    "需要正向反馈",
    "对抽象概念理解困难"
  ],
  "typicalInputPatterns": [
    "老师这是什么意思啊",
    "我不懂...",
    "太难了我不想学了",
    "哇好厉害！然后呢？"
  ]
}
```

### 3.2 评测目标 (EvalTarget)

```typescript
// config/eval/targets/{targetId}.json
interface EvalTarget {
  id: string;                    // 唯一标识，如 "edu_simple_modify_v1"
  name: string;                  // 显示名称
  description: string;           // 评测目标描述

  // 评测范围
  targetType: "scene" | "sceneGroup";
  sceneId?: string;              // targetType=scene 时使用
  sceneGroupId?: string;         // targetType=sceneGroup 时使用

  // 场景优化目标（语义化描述）
  optimizationGoals?: string[];  // 如 ["回复更有亲和力", "引导更循序渐进"]

  // 关联的评测集
  datasetIds: string[];          // 关联的评测集ID列表

  // 评测配置
  evalConfig: {
    judgeModel?: ModelConfig;    // 评判模型配置，不填则用执行模型
    failureReasons: string[];    // 该目标适用的失败原因（从全局库选择）
    passThreshold?: number;      // 通过率阈值，默认 1.0 (100%)
  };

  // 元信息
  createdAt: string;
  updatedAt: string;
}
```

### 3.3 评测集 (EvalDataset)

```typescript
// config/eval/datasets/{datasetId}.json
interface EvalDataset {
  id: string;                    // 唯一标识
  targetId: string;              // 所属评测目标
  name: string;                  // 显示名称
  description?: string;          // 描述

  // 生成来源
  source: {
    type: "manual" | "ai_generated" | "ai_augmented" | "production";
    rolePersonaId?: string;      // AI生成时使用的角色
    generatedAt?: string;
    generatorModel?: string;
    seedDatasetId?: string;      // ai_augmented 时，基于哪个种子集
    augmentStrategy?: string;    // 扩展策略，如 "variation", "edge_case", "role_switch"
  };

  // 评测用例
  cases: EvalCase[];

  // 元信息
  createdAt: string;
  updatedAt: string;
}

interface EvalCase {
  id: string;                    // case 唯一标识
  sessionId: string;             // 会话ID，标识一次完整多轮对话

  // 对话轮次
  turns: EvalTurn[];

  // 整体标注
  overallExpectation?: string;   // 整体预期（语义化）
  tags?: string[];               // 标签，如 ["edge_case", "regression"]
}

/**
 * 评测轮次
 *
 * 数据流向：
 * ┌─────────────────────────────────────────────────────────────────┐
 * │  评测集创建时（人工/AI 编写）                                      │
 * │  ├─ input: 模拟用户输入                                          │
 * │  └─ expectedSemantics/expectedOutput: 预期 AI 如何回复            │
 * └─────────────────────────────────────────────────────────────────┘
 *                              ↓
 * ┌─────────────────────────────────────────────────────────────────┐
 * │  评测运行时（自动填充）                                            │
 * │  ├─ actualOutput: 场景执行后 AI 的真实回复                        │
 * │  └─ judgement: 对比预期与实际后的评判结果                          │
 * └─────────────────────────────────────────────────────────────────┘
 */
interface EvalTurn {
  turnId: string;                // 轮次ID
  input: string;                 // 用户输入（模拟学生发言）

  // ========== 预期输出（评测集创建时定义，三种形式至少填一种）==========
  expectedOutput?: string;       // 精确预期（完整回复文本，适合有标准答案的场景）
  expectedSemantics?: string;    // 语义预期，如 "鼓励学生，语气轻松"（推荐，更灵活）
  expectedConstraints?: {        // 约束条件（可与语义预期组合使用）
    maxLength?: number;
    mustInclude?: string[];
    mustNotInclude?: string[];
    tone?: string;               // 如 "温暖"、"专业"
  };

  // ========== 执行结果（评测运行时自动填充）==========
  actualOutput?: string;         // AI 实际回复，由 Driver 执行场景后收集

  // ========== 评判结果（评测运行时自动填充）==========
  judgement?: {
    pass: boolean;               // 是否通过
    failureReasons?: string[];   // 失败原因列表（从全局失败原因库中选择）
    score?: number;              // 可选评分 0-1
    analysis?: string;           // AI 评判分析说明
  };
}
```

### 3.4 执行记录 (EvalRun)

```typescript
// data/eval/runs/{runId}.json
interface EvalRun {
  id: string;                    // 运行ID
  targetId: string;              // 评测目标
  datasetIds: string[];          // 本次运行的评测集

  // 场景配置版本
  sceneVersion: {
    sceneId: string;
    versionTag: string;          // 如 "educationSimpleModify_opt_251127_01"
    configSnapshot: SceneDefinition; // 完整配置快照
  };

  // 执行配置
  executeConfig: {
    model: ModelConfig;
    judgeModel?: ModelConfig;
  };

  // 执行结果
  status: "pending" | "running" | "completed" | "failed";
  results: EvalCaseResult[];

  // 统计
  stats: {
    total: number;
    passed: number;
    failed: number;
    passRate: number;
    failureReasonBreakdown: Record<string, number>; // 各失败原因计数
  };

  // 时间
  startedAt: string;
  completedAt?: string;
  durationMs?: number;
}

interface EvalCaseResult {
  caseId: string;
  sessionId: string;
  status: "passed" | "failed" | "error";

  turns: {
    turnId: string;
    input: string;
    actualOutput: string;
    judgement: {
      pass: boolean;
      failureReasons?: string[];
      analysis?: string;
    };
    latencyMs: number;
    tokenUsage?: LlmTokenUsage;
  }[];

  // 场景链执行情况（如果是 sceneGroup）
  sceneExecutions?: {
    sceneId: string;
    status: "success" | "failed";
    error?: string;
  }[];

  error?: string;
}
```

### 3.5 场景配置版本 (SceneVersion)

```typescript
// data/eval/sceneVersions/{sceneId}/{versionTag}.json
interface SceneVersion {
  sceneId: string;
  versionTag: string;            // 如 "educationSimpleModify_opt_251127_01"

  // 完整配置
  config: SceneDefinition;

  // 变更信息
  changes?: {
    fromVersion?: string;        // 基于哪个版本
    changedFields: string[];     // 改动的字段
    changeReason: string;        // 改动原因
    changeDetails: {             // 具体改动
      field: string;
      before: string;
      after: string;
      reason: string;
    }[];
  };

  // 评测结果摘要
  evalSummary?: {
    lastRunId: string;
    passRate: number;
    comparedToBaseline?: {
      baselineVersion: string;
      passRateDiff: number;      // 正数表示提升
      regressions: string[];     // 回退的 case IDs
    };
  };

  // 状态
  status: "draft" | "testing" | "approved" | "deployed" | "archived";

  // 元信息
  createdAt: string;
  createdBy: "ai" | "human";
  approvedAt?: string;
  approvedBy?: string;
}
```

### 3.6 循环优化任务 (OptimizationLoop)

```typescript
// data/eval/loops/{loopId}.json
interface OptimizationLoop {
  id: string;                    // 循环任务ID
  targetId: string;              // 评测目标
  datasetIds: string[];          // 使用的评测集

  // 配置
  config: {
    maxIterations: number;       // 最大循环次数
    stopOnPassRate?: number;     // 提前停止阈值
    executeModel: ModelConfig;
    judgeModel?: ModelConfig;
    optimizerModel?: ModelConfig;
  };

  // 基线版本（循环开始前的配置）
  baselineVersion: {
    sceneId: string;
    versionTag: string;
    passRate: number;
  };

  // 迭代记录
  iterations: OptimizationIteration[];

  // 状态
  status: "running" | "completed" | "stopped" | "failed";
  currentIteration: number;

  // 最终选择
  selectedVersion?: {
    versionTag: string;
    selectedAt: string;
    selectedBy: "auto" | "human";
    reason?: string;
  };

  // 时间
  startedAt: string;
  completedAt?: string;
}

interface OptimizationIteration {
  iteration: number;             // 第几轮，从 1 开始

  // 该轮使用的配置版本
  versionTag: string;

  // 评测结果
  runId: string;
  passRate: number;
  passedCount: number;
  failedCount: number;

  // 与上一轮对比
  improvement?: {
    passRateDiff: number;        // 通过率变化
    newlyPassed: string[];       // 新通过的 case
    regressions: string[];       // 回退的 case
  };

  // 归因结果
  attributionId?: string;
  topFailureReasons?: string[];

  // 下一轮优化（如果不是最后一轮）
  nextVersionTag?: string;
  optimizationSummary?: string;  // 优化摘要

  // 时间
  startedAt: string;
  completedAt: string;
  durationMs: number;
}
```

### 3.7 全局失败原因库 (FailureReasonRegistry)

```typescript
// config/eval/failureReasons.json
interface FailureReasonRegistry {
  categories: FailureCategory[];
}

interface FailureCategory {
  id: string;                    // 如 "language"
  name: string;                  // 如 "语言规范"
  reasons: FailureReason[];
}

interface FailureReason {
  id: string;                    // 如 "language_mismatch"
  name: string;                  // 如 "语言不符合要求"
  description: string;           // 详细说明
  severity: "critical" | "major" | "minor";
  examples?: string[];           // 示例
}
```

---

## 四、核心模块设计

### 4.1 评测集生成器 (EvalDatasetGenerator)

```typescript
// server/eval/generator/datasetGenerator.ts

interface DatasetGeneratorConfig {
  targetId: string;              // 评测目标
  rolePersonaIds: string[];      // 使用的角色列表
  turnsPerCase: number;          // 每个 case 的对话轮数
  casesPerRole: number;          // 每个角色生成的 case 数
  optimizationGoals?: string[];  // 场景优化目标
  generatorModel: ModelConfig;   // 生成用的模型
}

// 二次创作配置
interface DatasetAugmentConfig {
  seedDatasetId: string;         // 种子评测集 ID
  strategy: AugmentStrategy;     // 扩展策略
  rolePersonaIds?: string[];     // 可选：用其他角色改写
  multiplier?: number;           // 扩展倍数，默认 3
  generatorModel: ModelConfig;
}

type AugmentStrategy =
  | "variation"      // 变体：基于原 case 生成相似但不同的输入
  | "edge_case"      // 边界：基于原 case 生成边界情况
  | "role_switch"    // 换角色：用不同角色特征改写输入
  | "difficulty"     // 难度梯度：生成更简单/更复杂的版本
  | "adversarial";   // 对抗：生成可能导致失败的输入

class EvalDatasetGenerator {
  /**
   * 从零生成评测集
   *
   * 流程：
   * 1. 加载评测目标和场景配置
   * 2. 加载角色配置
   * 3. 构建生成 prompt
   * 4. 调用 LLM 生成对话
   * 5. 解析并验证生成结果
   * 6. 保存评测集
   */
  async generate(config: DatasetGeneratorConfig): Promise<EvalDataset> {
    // 1. 加载配置
    const target = await this.loadEvalTarget(config.targetId);
    const scene = await this.loadSceneDefinition(target);
    const roles = await this.loadRolePersonas(config.rolePersonaIds);

    // 2. 生成每个角色的 cases
    const allCases: EvalCase[] = [];
    for (const role of roles) {
      const cases = await this.generateCasesForRole(
        scene,
        role,
        config,
        target.optimizationGoals
      );
      allCases.push(...cases);
    }

    // 3. 构建评测集
    const dataset: EvalDataset = {
      id: this.generateDatasetId(),
      targetId: config.targetId,
      name: `Auto-generated for ${target.name}`,
      source: {
        type: "ai_generated",
        generatedAt: new Date().toISOString(),
        generatorModel: config.generatorModel.openaiModel,
      },
      cases: allCases,
      createdAt: new Date().toISOString(),
      updatedAt: new Date().toISOString(),
    };

    // 4. 保存
    await this.saveDataset(dataset);

    return dataset;
  }

  /**
   * 基于种子集二次创作
   *
   * 支持策略：
   * - variation: 生成相似但不同的变体
   * - edge_case: 基于原 case 推导边界情况
   * - role_switch: 用不同角色特征改写
   * - difficulty: 生成不同难度版本
   * - adversarial: 生成对抗性输入
   */
  async augment(config: DatasetAugmentConfig): Promise<EvalDataset> {
    // 1. 加载种子集
    const seedDataset = await this.loadDataset(config.seedDatasetId);
    const target = await this.loadEvalTarget(seedDataset.targetId);
    const scene = await this.loadSceneDefinition(target);

    // 2. 加载角色（如果是 role_switch 策略）
    const roles = config.rolePersonaIds
      ? await this.loadRolePersonas(config.rolePersonaIds)
      : [];

    // 3. 对每个种子 case 进行扩展
    const augmentedCases: EvalCase[] = [];
    for (const seedCase of seedDataset.cases) {
      const newCases = await this.augmentCase(
        seedCase,
        scene,
        config.strategy,
        roles,
        config.multiplier || 3,
        config.generatorModel
      );
      augmentedCases.push(...newCases);
    }

    // 4. 构建新评测集
    const dataset: EvalDataset = {
      id: this.generateDatasetId(),
      targetId: seedDataset.targetId,
      name: `Augmented from ${seedDataset.name} (${config.strategy})`,
      source: {
        type: "ai_augmented",
        seedDatasetId: config.seedDatasetId,
        augmentStrategy: config.strategy,
        generatedAt: new Date().toISOString(),
        generatorModel: config.generatorModel.openaiModel,
      },
      cases: augmentedCases,
      createdAt: new Date().toISOString(),
      updatedAt: new Date().toISOString(),
    };

    await this.saveDataset(dataset);
    return dataset;
  }

  private async augmentCase(
    seedCase: EvalCase,
    scene: SceneDefinition,
    strategy: AugmentStrategy,
    roles: RolePersona[],
    multiplier: number,
    model: ModelConfig
  ): Promise<EvalCase[]> {
    const prompt = this.buildAugmentPrompt(seedCase, scene, strategy, roles, multiplier);
    const response = await this.llm.generate(prompt, model);
    return this.parseGeneratedCases(response, `augment_${strategy}`);
  }

  private buildAugmentPrompt(
    seedCase: EvalCase,
    scene: SceneDefinition,
    strategy: AugmentStrategy,
    roles: RolePersona[],
    multiplier: number
  ): string {
    const strategyInstructions: Record<AugmentStrategy, string> = {
      variation: `
基于原始 case，生成 ${multiplier} 个变体：
- 保持相同的对话意图和流程
- 改变具体的措辞、表达方式
- 可以调整细节但不改变核心场景`,
      edge_case: `
基于原始 case，生成 ${multiplier} 个边界情况：
- 极端输入（很长/很短/特殊字符）
- 模糊或歧义的表达
- 容易被误解的输入
- 测试系统鲁棒性的场景`,
      role_switch: `
用以下不同角色改写原始 case：
${roles.map(r => `- ${r.name}: ${r.personality}`).join('\n')}
每个角色生成 1 个改写版本，保持对话意图不变但符合角色特征`,
      difficulty: `
基于原始 case，生成不同难度版本：
- 1 个更简单的版本（更直接、更清晰的表达）
- 1 个中等难度版本
- 1 个更复杂的版本（更隐晦、需要更多推理）`,
      adversarial: `
基于原始 case，生成 ${multiplier} 个对抗性输入：
- 可能导致 AI 回复不当的输入
- 测试 AI 边界处理能力的输入
- 容易触发常见失败原因的输入
- 但输入本身应该是合理的用户行为，不是恶意攻击`
    };

    return `
你是一个评测数据扩展专家。请基于种子 case 生成更多评测用例。

## 场景配置
- 角色人设: ${scene.personality}
- 核心目标: ${scene.goals}

## 种子 Case
\`\`\`json
${JSON.stringify(seedCase, null, 2)}
\`\`\`

## 扩展策略
${strategyInstructions[strategy]}

## 输出格式 (JSON)
{
  "cases": [
    {
      "sessionId": "augment_001",
      "description": "扩展描述",
      "sourceCase": "${seedCase.id}",
      "turns": [...]
    }
  ]
}

请生成:
`;
  }

  private async generateCasesForRole(
    scene: SceneDefinition,
    role: RolePersona,
    config: DatasetGeneratorConfig,
    optimizationGoals?: string[]
  ): Promise<EvalCase[]> {
    const prompt = this.buildGeneratorPrompt(scene, role, config, optimizationGoals);
    const response = await this.llm.generate(prompt, config.generatorModel);
    return this.parseGeneratedCases(response, role.id);
  }

  private buildGeneratorPrompt(
    scene: SceneDefinition,
    role: RolePersona,
    config: DatasetGeneratorConfig,
    optimizationGoals?: string[]
  ): string {
    return `
你是一个评测数据生成专家。请根据以下信息生成评测用例。

## 场景配置
- 角色人设: ${scene.personality}
- 核心目标: ${scene.goals}
- 领域知识: ${scene.knowledge || '无'}

## 你要扮演的用户角色
- 角色名称: ${role.name}
- 角色特征: ${role.personality}
- 行为特点: ${role.characteristics.join(', ')}
- 典型输入示例: ${role.typicalInputPatterns.join(', ')}

## 场景优化目标
${optimizationGoals?.length ? optimizationGoals.map(g => `- ${g}`).join('\n') : '无特殊优化目标，生成通用评测用例'}

## 生成要求
1. 生成 ${config.casesPerRole} 个独立的对话 case
2. 每个 case 包含 ${config.turnsPerCase} 轮对话
3. 每轮包含：用户输入(input) 和 预期语义(expectedSemantics)
4. 预期语义描述 AI 应该如何回复，而不是具体回复内容
5. 覆盖正常场景和边界场景

## 输出格式 (JSON)
{
  "cases": [
    {
      "sessionId": "session_001",
      "description": "case 描述",
      "turns": [
        {
          "turnId": "turn_001",
          "input": "用户说的话",
          "expectedSemantics": "AI 应该如何回应的语义描述"
        }
      ]
    }
  ]
}

请生成:
`;
  }
}
```

### 4.2 评测执行引擎 (EvalExecutor)

```typescript
// server/eval/executor/evalExecutor.ts

interface EvalExecutorConfig {
  targetId: string;
  datasetIds: string[];
  sceneVersionTag?: string;      // 不填则用当前配置
  executeModel?: ModelConfig;
  judgeModel?: ModelConfig;
  parallel?: number;             // 并行度，默认 1
}

class EvalExecutor {
  private driver: AgentDriver;
  private judgeEngine: JudgeEngine;

  /**
   * 执行评测
   *
   * 流程：
   * 1. 加载评测目标、评测集、场景配置
   * 2. 创建执行记录
   * 3. 遍历每个 case，执行场景
   * 4. 收集 actual_output
   * 5. 调用评判引擎判断
   * 6. 更新统计并保存
   */
  async execute(config: EvalExecutorConfig): Promise<EvalRun> {
    // 1. 初始化
    const target = await this.loadEvalTarget(config.targetId);
    const datasets = await this.loadDatasets(config.datasetIds);
    const sceneConfig = await this.loadSceneConfig(target, config.sceneVersionTag);

    // 2. 创建执行记录
    const run = this.createEvalRun(config, target, sceneConfig);
    await this.saveRun(run);

    // 3. 执行每个 case
    for (const dataset of datasets) {
      for (const evalCase of dataset.cases) {
        try {
          const result = await this.executeCase(
            evalCase,
            target,
            sceneConfig,
            config
          );
          run.results.push(result);

          // 场景链中某个场景失败，整个 case 失败
          if (result.status === "failed" && target.targetType === "sceneGroup") {
            const failedScene = result.sceneExecutions?.find(s => s.status === "failed");
            if (failedScene) {
              result.error = `Scene ${failedScene.sceneId} failed: ${failedScene.error}`;
            }
          }
        } catch (error) {
          run.results.push({
            caseId: evalCase.id,
            sessionId: evalCase.sessionId,
            status: "error",
            turns: [],
            error: error.message,
          });
        }

        // 实时保存进度
        await this.saveRun(run);
      }
    }

    // 4. 计算统计
    run.stats = this.calculateStats(run.results, target.evalConfig.failureReasons);
    run.status = "completed";
    run.completedAt = new Date().toISOString();

    await this.saveRun(run);
    return run;
  }

  private async executeCase(
    evalCase: EvalCase,
    target: EvalTarget,
    sceneConfig: SceneDefinition,
    config: EvalExecutorConfig
  ): Promise<EvalCaseResult> {
    const result: EvalCaseResult = {
      caseId: evalCase.id,
      sessionId: evalCase.sessionId,
      status: "passed",
      turns: [],
      sceneExecutions: [],
    };

    // 创建会话
    const sessionId = `eval_${evalCase.sessionId}_${Date.now()}`;

    for (const turn of evalCase.turns) {
      const startTime = Date.now();

      // 执行场景
      let actualOutput: string;
      if (target.targetType === "scene") {
        const response = await this.driver.runScene(
          target.sceneId!,
          turn.input,
          { sessionId }
        );
        actualOutput = response.responseText;
      } else {
        // 场景链执行
        const response = await this.driver.runSceneGroup(
          target.sceneGroupId!,
          turn.input,
          { sessionId }
        );
        actualOutput = response.finalPrompt || response.scenes.at(-1)?.responseText || "";

        // 记录每个场景的执行状态
        result.sceneExecutions = response.scenes.map(s => ({
          sceneId: s.sceneId,
          status: s.status,
          error: s.error,
        }));

        // 如果有场景失败，整个 case 失败
        if (response.scenes.some(s => s.status === "failed")) {
          result.status = "failed";
          return result;
        }
      }

      // 评判
      const judgement = await this.judgeEngine.judge(
        turn,
        actualOutput,
        target.evalConfig.failureReasons,
        config.judgeModel
      );

      result.turns.push({
        turnId: turn.turnId,
        input: turn.input,
        actualOutput,
        judgement,
        latencyMs: Date.now() - startTime,
      });

      // 任何一轮失败，整个 case 失败
      if (!judgement.pass) {
        result.status = "failed";
      }
    }

    return result;
  }
}
```

### 4.3 评判引擎 (JudgeEngine)

```typescript
// server/eval/judge/judgeEngine.ts

class JudgeEngine {
  /**
   * 评判单轮对话
   *
   * 评判策略：
   * 1. 如果有 expectedOutput，做精确/模糊匹配
   * 2. 如果有 expectedSemantics，用 LLM 语义判断
   * 3. 如果有 expectedConstraints，做规则检查
   * 4. 综合所有结果
   */
  async judge(
    turn: EvalTurn,
    actualOutput: string,
    failureReasons: string[],
    judgeModel?: ModelConfig
  ): Promise<{ pass: boolean; failureReasons?: string[]; analysis?: string }> {
    const failures: string[] = [];
    let analysis = "";

    // 1. 约束检查（规则）
    if (turn.expectedConstraints) {
      const constraintResult = this.checkConstraints(actualOutput, turn.expectedConstraints);
      if (!constraintResult.pass) {
        failures.push(...constraintResult.violations);
      }
    }

    // 2. 语义评判（LLM）
    if (turn.expectedSemantics || turn.expectedOutput) {
      const semanticResult = await this.semanticJudge(
        turn,
        actualOutput,
        failureReasons,
        judgeModel
      );
      if (!semanticResult.pass) {
        failures.push(...(semanticResult.failureReasons || []));
      }
      analysis = semanticResult.analysis || "";
    }

    return {
      pass: failures.length === 0,
      failureReasons: failures.length > 0 ? failures : undefined,
      analysis,
    };
  }

  private checkConstraints(
    actualOutput: string,
    constraints: EvalTurn["expectedConstraints"]
  ): { pass: boolean; violations: string[] } {
    const violations: string[] = [];

    if (constraints?.maxLength && actualOutput.length > constraints.maxLength) {
      violations.push("回复超长");
    }

    if (constraints?.mustInclude) {
      for (const keyword of constraints.mustInclude) {
        if (!actualOutput.includes(keyword)) {
          violations.push(`遗漏关键信息: ${keyword}`);
        }
      }
    }

    if (constraints?.mustNotInclude) {
      for (const keyword of constraints.mustNotInclude) {
        if (actualOutput.includes(keyword)) {
          violations.push(`包含禁止内容: ${keyword}`);
        }
      }
    }

    return { pass: violations.length === 0, violations };
  }

  private async semanticJudge(
    turn: EvalTurn,
    actualOutput: string,
    failureReasons: string[],
    judgeModel?: ModelConfig
  ): Promise<{ pass: boolean; failureReasons?: string[]; analysis?: string }> {
    const prompt = `
你是一个 AI 回复质量评判专家。请评判以下回复是否符合预期。

## 用户输入
${turn.input}

## AI 实际回复
${actualOutput}

## 预期
${turn.expectedSemantics ? `语义预期: ${turn.expectedSemantics}` : ""}
${turn.expectedOutput ? `参考回复: ${turn.expectedOutput}` : ""}

## 可选的失败原因
${failureReasons.map(r => `- ${r}`).join('\n')}

## 评判要求
1. 判断实际回复是否满足预期
2. 如果不满足，从上述失败原因中选择适用的
3. 给出简短的分析说明

## 输出格式 (JSON)
{
  "pass": true/false,
  "failureReasons": ["选中的失败原因"],
  "analysis": "分析说明"
}
`;

    const response = await this.llm.generate(prompt, judgeModel);
    return JSON.parse(response);
  }
}
```

### 4.4 归因引擎 (AttributionEngine)

```typescript
// server/eval/attribution/attributionEngine.ts

/**
 * 归因输入类型
 *
 * 支持三种归因场景：
 * 1. 基于评测运行结果的批量归因
 * 2. 基于单个对话轨迹的归因（含人工反馈）
 * 3. 基于整体对话质量的轨迹优化
 */
type AttributionInput =
  | { type: "eval_run"; runId: string }
  | { type: "conversation"; conversation: ConversationTrace; feedback?: HumanFeedback }
  | { type: "trajectory_optimization"; conversations: ConversationTrace[]; goal: string };

// 完整对话轨迹
interface ConversationTrace {
  sessionId: string;
  sceneId: string;
  sceneGroupId?: string;

  // 完整对话历史
  turns: {
    turnIndex: number;
    input: string;              // 用户输入
    output: string;             // AI 回复
    timestamp: string;
    toolCalls?: ToolCallInfo[]; // 工具调用记录
  }[];

  // 场景配置快照
  sceneConfig: SceneDefinition;
}

// 人工反馈
interface HumanFeedback {
  // 反馈针对的位置
  scope: "turn" | "conversation";
  turnIndex?: number;           // scope=turn 时指定哪一轮

  // 反馈内容
  rating: "positive" | "negative";
  feedbackText?: string;        // 自由文本反馈，如 "这里回复太生硬了"
  selectedReasons?: string[];   // 从失败原因库中选择
  expectedBehavior?: string;    // 期望的行为描述
}

interface AttributionResult {
  inputType: AttributionInput["type"];
  targetId?: string;

  // 整体分析
  overallAnalysis: string;

  // 对话轨迹分析（新增）
  trajectoryAnalysis?: {
    flowAssessment: string;     // 对话流程评估
    turningPoints: {            // 关键转折点
      turnIndex: number;
      description: string;
      impact: "positive" | "negative" | "neutral";
    }[];
    contextIssues: string[];    // 上下文相关问题
  };

  // 失败原因分布
  failureDistribution: {
    reason: string;
    count: number;
    percentage: number;
    representativeCases: string[];
  }[];

  // 根因分析
  rootCauses: {
    configField: string;
    issue: string;
    evidence: string[];
    suggestedFix: string;
    confidence: number;
    // 新增：关联的对话上下文
    relatedTurns?: number[];    // 相关的轮次索引
  }[];

  // 关联的配置片段
  relatedConfigSegments: {
    field: string;
    content: string;
    issues: string[];
  }[];
}

class AttributionEngine {
  /**
   * 统一归因入口
   */
  async analyze(input: AttributionInput): Promise<AttributionResult> {
    switch (input.type) {
      case "eval_run":
        return this.analyzeEvalRun(input.runId);
      case "conversation":
        return this.analyzeConversation(input.conversation, input.feedback);
      case "trajectory_optimization":
        return this.analyzeTrajectories(input.conversations, input.goal);
    }
  }

  /**
   * 基于评测运行结果的批量归因
   */
  private async analyzeEvalRun(runId: string): Promise<AttributionResult> {
    const run = await this.loadEvalRun(runId);
    const target = await this.loadEvalTarget(run.targetId);
    const sceneConfig = run.sceneVersion.configSnapshot;

    const failedCases = run.results.filter(r => r.status === "failed");
    if (failedCases.length === 0) {
      return this.createEmptyResult("eval_run", run.targetId);
    }

    // 不只是看单轮失败，还要分析完整对话轨迹
    const trajectoryAnalysis = await this.analyzeConversationFlows(
      failedCases,
      sceneConfig
    );

    const clusters = this.clusterByFailureReason(failedCases);
    const rootCauses = await this.analyzeRootCausesWithContext(
      clusters,
      sceneConfig,
      target,
      trajectoryAnalysis
    );

    return {
      inputType: "eval_run",
      targetId: run.targetId,
      overallAnalysis: await this.generateOverallAnalysis(clusters, rootCauses),
      trajectoryAnalysis,
      failureDistribution: this.buildDistribution(clusters, failedCases.length),
      rootCauses,
      relatedConfigSegments: this.extractRelatedSegments(sceneConfig, rootCauses),
    };
  }

  /**
   * 基于单个对话轨迹的归因（支持人工反馈）
   *
   * 使用场景：
   * - 用户对某轮回复点了踩，并给出反馈
   * - 做课老师发现某个对话流程有问题
   */
  private async analyzeConversation(
    conversation: ConversationTrace,
    feedback?: HumanFeedback
  ): Promise<AttributionResult> {
    const prompt = this.buildConversationAnalysisPrompt(conversation, feedback);
    const analysis = await this.llm.generate(prompt);

    return JSON.parse(analysis);
  }

  private buildConversationAnalysisPrompt(
    conversation: ConversationTrace,
    feedback?: HumanFeedback
  ): string {
    const feedbackSection = feedback ? `
## 人工反馈
- 反馈范围: ${feedback.scope === "turn" ? `第 ${feedback.turnIndex} 轮` : "整体对话"}
- 评价: ${feedback.rating === "positive" ? "正面" : "负面"}
${feedback.feedbackText ? `- 反馈内容: ${feedback.feedbackText}` : ""}
${feedback.selectedReasons?.length ? `- 选择的原因: ${feedback.selectedReasons.join(", ")}` : ""}
${feedback.expectedBehavior ? `- 期望行为: ${feedback.expectedBehavior}` : ""}
` : "";

    return `
你是一个 AI 对话质量分析专家。请分析以下对话轨迹，找出问题根因。

## 场景配置
\`\`\`json
{
  "personality": ${JSON.stringify(conversation.sceneConfig.personality)},
  "goals": ${JSON.stringify(conversation.sceneConfig.goals)},
  "knowledge": ${JSON.stringify(conversation.sceneConfig.knowledge || "")}
}
\`\`\`

## 完整对话轨迹
${conversation.turns.map((t, i) => `
### 第 ${i + 1} 轮
用户: ${t.input}
AI: ${t.output}
${t.toolCalls?.length ? `工具调用: ${t.toolCalls.map(tc => tc.name).join(", ")}` : ""}
`).join("\n")}
${feedbackSection}

## 分析任务
请从以下维度分析：

1. **对话流程评估**：整体对话是否流畅？是否符合场景目标？
2. **关键转折点**：哪些轮次是关键的？是正面还是负面影响？
3. **上下文问题**：AI 是否正确理解和利用了上下文？
4. **根因定位**：问题出在配置的哪个部分？如何修复？

${feedback ? `
5. **反馈响应**：针对人工反馈，分析 AI 为什么会产生这样的回复，如何避免？
` : ""}

## 输出格式 (JSON)
{
  "inputType": "conversation",
  "overallAnalysis": "整体分析",
  "trajectoryAnalysis": {
    "flowAssessment": "对话流程评估",
    "turningPoints": [
      {"turnIndex": 2, "description": "描述", "impact": "negative"}
    ],
    "contextIssues": ["上下文问题1"]
  },
  "failureDistribution": [],
  "rootCauses": [
    {
      "configField": "personality",
      "issue": "问题描述",
      "evidence": ["证据"],
      "suggestedFix": "建议",
      "confidence": 0.8,
      "relatedTurns": [2, 3]
    }
  ],
  "relatedConfigSegments": []
}
`;
  }

  /**
   * 基于多个对话轨迹的整体优化分析
   *
   * 使用场景：
   * - 希望整体提升对话质量，而不只是修复 badcase
   * - 分析多个对话的共性问题
   */
  private async analyzeTrajectories(
    conversations: ConversationTrace[],
    goal: string
  ): Promise<AttributionResult> {
    const prompt = `
你是一个 AI 对话系统优化专家。请分析以下多个对话轨迹，找出共性问题和优化方向。

## 优化目标
${goal}

## 对话轨迹（共 ${conversations.length} 个）
${conversations.map((conv, i) => `
### 对话 ${i + 1} (${conv.sessionId})
${conv.turns.map((t, j) => `[${j + 1}] 用户: ${t.input}\n    AI: ${t.output}`).join("\n")}
`).join("\n---\n")}

## 场景配置（以第一个对话为准）
\`\`\`json
${JSON.stringify({
  personality: conversations[0].sceneConfig.personality,
  goals: conversations[0].sceneConfig.goals,
}, null, 2)}
\`\`\`

## 分析任务
1. 找出多个对话中的**共性问题**（而非个例）
2. 分析对话流程的**整体模式**是否合理
3. 给出**系统性优化建议**，而非针对单个 case 的修复

## 输出格式 (JSON)
{
  "inputType": "trajectory_optimization",
  "overallAnalysis": "整体分析",
  "trajectoryAnalysis": {
    "flowAssessment": "对话流程模式评估",
    "turningPoints": [],
    "contextIssues": ["共性上下文问题"]
  },
  "failureDistribution": [],
  "rootCauses": [
    {
      "configField": "goals",
      "issue": "共性问题",
      "evidence": ["对话1/3/5 都出现了..."],
      "suggestedFix": "系统性建议",
      "confidence": 0.9
    }
  ],
  "relatedConfigSegments": []
}
`;

    const analysis = await this.llm.generate(prompt);
    return JSON.parse(analysis);
  }

  /**
   * 分析对话流程（用于评测运行结果）
   */
  private async analyzeConversationFlows(
    failedCases: EvalCaseResult[],
    sceneConfig: SceneDefinition
  ): Promise<AttributionResult["trajectoryAnalysis"]> {
    // 提取有代表性的失败对话
    const representativeCases = this.selectRepresentativeCases(failedCases, 5);

    const prompt = `
分析以下失败对话的流程模式：

${representativeCases.map((c, i) => `
### 对话 ${i + 1}
${c.turns.map((t, j) => `[${j + 1}] 输入: ${t.input}\n    输出: ${t.actualOutput}\n    评判: ${t.judgement.pass ? "通过" : `失败(${t.judgement.failureReasons?.join(",")})`}`).join("\n")}
`).join("\n---\n")}

请分析：
1. 这些对话的流程有什么共性问题？
2. 失败通常发生在什么阶段？
3. 上下文理解是否有问题？

输出 JSON: {"flowAssessment": "", "turningPoints": [], "contextIssues": []}
`;

    const response = await this.llm.generate(prompt);
    return JSON.parse(response);
  }

  /**
   * 带上下文的根因分析
   */
  private async analyzeRootCausesWithContext(
    clusters: Map<string, EvalCaseResult[]>,
    sceneConfig: SceneDefinition,
    target: EvalTarget,
    trajectoryAnalysis: AttributionResult["trajectoryAnalysis"]
  ): Promise<AttributionResult["rootCauses"]> {
    const prompt = `
你是一个 AI 系统配置专家，擅长分析问题根因。

## 当前场景配置
\`\`\`json
{
  "personality": ${JSON.stringify(sceneConfig.personality)},
  "goals": ${JSON.stringify(sceneConfig.goals)},
  "knowledge": ${JSON.stringify(sceneConfig.knowledge)},
  "userContext": ${JSON.stringify(sceneConfig.userContext)}
}
\`\`\`

## 场景优化目标
${target.optimizationGoals?.join('\n') || '无'}

## 对话流程分析结果
- 流程评估: ${trajectoryAnalysis?.flowAssessment || "无"}
- 上下文问题: ${trajectoryAnalysis?.contextIssues?.join("; ") || "无"}
- 关键转折点: ${trajectoryAnalysis?.turningPoints?.map(t => `第${t.turnIndex}轮(${t.impact}): ${t.description}`).join("; ") || "无"}

## 失败案例聚类
${this.formatClustersForPrompt(clusters)}

## 任务
结合对话流程分析和失败案例，找出配置中的根本问题：

1. 定位问题出在哪个配置字段
2. 问题是单轮的还是跨轮次的（上下文相关）
3. 给出修复建议
4. 标注相关的对话轮次

## 输出格式 (JSON)
{
  "rootCauses": [
    {
      "configField": "personality",
      "issue": "问题描述",
      "evidence": ["证据"],
      "suggestedFix": "建议",
      "confidence": 0.85,
      "relatedTurns": [2, 3]
    }
  ]
}
`;

    const response = await this.llm.generate(prompt);
    return JSON.parse(response).rootCauses;
  }
}
```

### 4.5 优化引擎 (OptimizationEngine)

```typescript
// server/eval/optimization/optimizationEngine.ts

interface OptimizationResult {
  runId: string;
  attributionId: string;

  // 新版本配置
  newVersion: SceneVersion;

  // 变更说明
  changeSummary: string;
  changeDetails: {
    field: string;
    before: string;
    after: string;
    reason: string;
  }[];

  // 预期效果
  expectedImprovements: string[];
}

class OptimizationEngine {
  /**
   * 生成优化配置
   *
   * 流程：
   * 1. 加载归因结果
   * 2. 加载当前配置
   * 3. 生成优化 prompt
   * 4. 调用 LLM 生成新配置
   * 5. 验证新配置格式
   * 6. 创建新版本
   */
  async optimize(
    runId: string,
    attribution: AttributionResult
  ): Promise<OptimizationResult> {
    // 1. 加载当前配置
    const run = await this.loadEvalRun(runId);
    const currentConfig = run.sceneVersion.configSnapshot;
    const target = await this.loadEvalTarget(run.targetId);

    // 2. 生成优化
    const optimizedConfig = await this.generateOptimizedConfig(
      currentConfig,
      attribution,
      target
    );

    // 3. 创建新版本
    const versionTag = this.generateVersionTag(run.sceneVersion.sceneId);
    const newVersion: SceneVersion = {
      sceneId: run.sceneVersion.sceneId,
      versionTag,
      config: optimizedConfig.config,
      changes: {
        fromVersion: run.sceneVersion.versionTag,
        changedFields: optimizedConfig.changedFields,
        changeReason: attribution.overallAnalysis,
        changeDetails: optimizedConfig.changeDetails,
      },
      status: "draft",
      createdAt: new Date().toISOString(),
      createdBy: "ai",
    };

    // 4. 保存
    await this.saveSceneVersion(newVersion);

    return {
      runId,
      attributionId: attribution.runId,
      newVersion,
      changeSummary: this.generateChangeSummary(optimizedConfig.changeDetails),
      changeDetails: optimizedConfig.changeDetails,
      expectedImprovements: optimizedConfig.expectedImprovements,
    };
  }

  private async generateOptimizedConfig(
    currentConfig: SceneDefinition,
    attribution: AttributionResult,
    target: EvalTarget
  ): Promise<{
    config: SceneDefinition;
    changedFields: string[];
    changeDetails: OptimizationResult["changeDetails"];
    expectedImprovements: string[];
  }> {
    const prompt = `
你是一个 AI 提示词优化专家。请根据问题分析优化以下配置。

## 当前配置
\`\`\`json
${JSON.stringify(currentConfig, null, 2)}
\`\`\`

## 问题分析
${attribution.overallAnalysis}

## 根因定位
${attribution.rootCauses.map(rc => `
- 字段: ${rc.configField}
- 问题: ${rc.issue}
- 建议: ${rc.suggestedFix}
- 置信度: ${rc.confidence}
`).join('\n')}

## 场景优化目标
${target.optimizationGoals?.join('\n') || '无特殊目标'}

## 优化要求
1. 只修改必要的字段，保持其他字段不变
2. 修改要具体、可验证
3. 不能改变场景的核心定位
4. 不能修改 tools、modelConfig 字段

## 输出格式 (JSON)
{
  "config": { /* 完整的优化后配置 */ },
  "changedFields": ["personality", "goals"],
  "changeDetails": [
    {
      "field": "personality",
      "before": "原内容",
      "after": "新内容",
      "reason": "修改原因"
    }
  ],
  "expectedImprovements": ["预期改善1", "预期改善2"]
}
`;

    const response = await this.llm.generate(prompt);
    return JSON.parse(response);
  }

  private generateVersionTag(sceneId: string): string {
    const date = new Date();
    const dateStr = date.toISOString().slice(2, 10).replace(/-/g, '');
    const seq = this.getNextSequence(sceneId, dateStr);
    return `${sceneId}_opt_${dateStr}_${seq.toString().padStart(2, '0')}`;
  }
}
```

### 4.6 循环优化引擎 (OptimizationLoopEngine)

```typescript
// server/eval/loop/optimizationLoopEngine.ts

class OptimizationLoopEngine {
  private executor: EvalExecutor;
  private attributor: AttributionEngine;
  private optimizer: OptimizationEngine;
  private regressionDetector: RegressionDetector;

  /**
   * 启动循环优化
   *
   * 流程：
   * 1. 用当前配置跑一次评测作为 baseline
   * 2. 循环：归因 → 优化 → 评测 → 对比
   * 3. 达到停止条件时结束
   * 4. 返回所有版本供用户选择
   */
  async startLoop(config: CreateOptimizationLoopRequest): Promise<OptimizationLoop> {
    // 1. 创建循环任务
    const loop = await this.createLoop(config);

    // 2. 跑 baseline
    const baselineRun = await this.executor.execute({
      targetId: config.targetId,
      datasetIds: config.datasetIds,
      executeModel: config.executeModel,
      judgeModel: config.judgeModel,
    });

    loop.baselineVersion.passRate = baselineRun.stats.passRate;
    await this.saveLoop(loop);

    // 3. 开始循环
    await this.runIterations(loop);

    return loop;
  }

  private async runIterations(loop: OptimizationLoop): Promise<void> {
    let currentVersionTag = loop.baselineVersion.versionTag;
    let previousRunId = loop.iterations[0]?.runId;

    for (let i = 1; i <= loop.config.maxIterations; i++) {
      loop.currentIteration = i;
      await this.saveLoop(loop);

      // 检查是否被手动停止
      if (loop.status === "stopped") break;

      const iteration: OptimizationIteration = {
        iteration: i,
        versionTag: currentVersionTag,
        runId: "",
        passRate: 0,
        passedCount: 0,
        failedCount: 0,
        startedAt: new Date().toISOString(),
        completedAt: "",
        durationMs: 0,
      };

      try {
        // 3.1 评测当前版本
        const run = await this.executor.execute({
          targetId: loop.targetId,
          datasetIds: loop.datasetIds,
          sceneVersionTag: currentVersionTag,
          executeModel: loop.config.executeModel,
          judgeModel: loop.config.judgeModel,
        });

        iteration.runId = run.id;
        iteration.passRate = run.stats.passRate;
        iteration.passedCount = run.stats.passed;
        iteration.failedCount = run.stats.failed;

        // 3.2 与上一轮对比
        if (previousRunId) {
          const comparison = await this.regressionDetector.check(previousRunId, run.id);
          iteration.improvement = {
            passRateDiff: comparison.passRateComparison.diff,
            newlyPassed: comparison.improvements.map(imp => imp.caseId),
            regressions: comparison.regressions.map(reg => reg.caseId),
          };
        }

        // 3.3 检查是否达到停止条件
        if (loop.config.stopOnPassRate && run.stats.passRate >= loop.config.stopOnPassRate) {
          iteration.completedAt = new Date().toISOString();
          iteration.durationMs = Date.now() - new Date(iteration.startedAt).getTime();
          loop.iterations.push(iteration);
          loop.status = "completed";
          await this.saveLoop(loop);
          break;
        }

        // 3.4 如果还没达到最大轮次，继续优化
        if (i < loop.config.maxIterations && run.stats.passRate < 1.0) {
          // 归因
          const attribution = await this.attributor.analyze(run.id);
          iteration.attributionId = attribution.runId;
          iteration.topFailureReasons = attribution.failureDistribution
            .slice(0, 3)
            .map(f => f.reason);

          // 优化
          const optimization = await this.optimizer.optimize(run.id, attribution);
          iteration.nextVersionTag = optimization.newVersion.versionTag;
          iteration.optimizationSummary = optimization.changeSummary;

          currentVersionTag = optimization.newVersion.versionTag;
        }

        iteration.completedAt = new Date().toISOString();
        iteration.durationMs = Date.now() - new Date(iteration.startedAt).getTime();
        loop.iterations.push(iteration);
        previousRunId = run.id;

      } catch (error) {
        iteration.completedAt = new Date().toISOString();
        loop.iterations.push(iteration);
        loop.status = "failed";
        await this.saveLoop(loop);
        throw error;
      }

      await this.saveLoop(loop);
    }

    if (loop.status === "running") {
      loop.status = "completed";
    }
    loop.completedAt = new Date().toISOString();
    await this.saveLoop(loop);
  }

  /**
   * 对比所有迭代版本
   */
  async compareIterations(loopId: string): Promise<IterationComparison> {
    const loop = await this.loadLoop(loopId);

    return {
      loopId,
      baseline: {
        versionTag: loop.baselineVersion.versionTag,
        passRate: loop.baselineVersion.passRate,
      },
      iterations: loop.iterations.map(iter => ({
        iteration: iter.iteration,
        versionTag: iter.versionTag,
        passRate: iter.passRate,
        passRateDiff: iter.passRate - loop.baselineVersion.passRate,
        regressionCount: iter.improvement?.regressions.length || 0,
        optimizationSummary: iter.optimizationSummary,
      })),
      recommendation: this.generateRecommendation(loop),
    };
  }

  /**
   * 生成推荐建议
   */
  private generateRecommendation(loop: OptimizationLoop): {
    recommendedVersion: string;
    reason: string;
  } {
    // 找出通过率最高且无回退的版本
    let best = loop.iterations[0];
    for (const iter of loop.iterations) {
      const noRegression = !iter.improvement?.regressions.length;
      const betterPassRate = iter.passRate > best.passRate;
      const samePassRateNoRegression = iter.passRate === best.passRate && noRegression;

      if (betterPassRate && noRegression) {
        best = iter;
      } else if (samePassRateNoRegression) {
        best = iter;
      }
    }

    return {
      recommendedVersion: best.versionTag,
      reason: `通过率 ${(best.passRate * 100).toFixed(1)}%，相比 baseline 提升 ${((best.passRate - loop.baselineVersion.passRate) * 100).toFixed(1)}%，无回退`,
    };
  }

  /**
   * 选择版本并部署
   */
  async selectAndDeploy(
    loopId: string,
    versionTag: string,
    reason?: string
  ): Promise<void> {
    const loop = await this.loadLoop(loopId);

    loop.selectedVersion = {
      versionTag,
      selectedAt: new Date().toISOString(),
      selectedBy: "human",
      reason,
    };

    // 部署到 sceneList.json
    await this.deployVersion(loop.baselineVersion.sceneId, versionTag);

    await this.saveLoop(loop);
  }
}

interface IterationComparison {
  loopId: string;
  baseline: {
    versionTag: string;
    passRate: number;
  };
  iterations: {
    iteration: number;
    versionTag: string;
    passRate: number;
    passRateDiff: number;
    regressionCount: number;
    optimizationSummary?: string;
  }[];
  recommendation: {
    recommendedVersion: string;
    reason: string;
  };
}
```

### 4.7 劣化检测 (RegressionDetector)

```typescript
// server/eval/regression/regressionDetector.ts

interface RegressionCheckResult {
  canDeploy: boolean;

  // 通过率对比
  passRateComparison: {
    baseline: number;
    current: number;
    diff: number;
  };

  // 回退的 case
  regressions: {
    caseId: string;
    baselineStatus: "passed";
    currentStatus: "failed";
    failureReasons: string[];
  }[];

  // 新通过的 case
  improvements: {
    caseId: string;
    baselineStatus: "failed";
    currentStatus: "passed";
  }[];

  // 结论
  summary: string;
}

class RegressionDetector {
  /**
   * 检查是否可以部署
   *
   * 规则：
   * 1. 整体通过率不下降
   * 2. 已有 case 不回退（原本通过的不能变成不通过）
   */
  async check(
    baselineRunId: string,
    currentRunId: string
  ): Promise<RegressionCheckResult> {
    const baseline = await this.loadEvalRun(baselineRunId);
    const current = await this.loadEvalRun(currentRunId);

    // 通过率对比
    const passRateComparison = {
      baseline: baseline.stats.passRate,
      current: current.stats.passRate,
      diff: current.stats.passRate - baseline.stats.passRate,
    };

    // 找出回退的 case
    const regressions: RegressionCheckResult["regressions"] = [];
    const improvements: RegressionCheckResult["improvements"] = [];

    const baselineMap = new Map(baseline.results.map(r => [r.caseId, r]));

    for (const currentResult of current.results) {
      const baselineResult = baselineMap.get(currentResult.caseId);
      if (!baselineResult) continue;

      if (baselineResult.status === "passed" && currentResult.status === "failed") {
        regressions.push({
          caseId: currentResult.caseId,
          baselineStatus: "passed",
          currentStatus: "failed",
          failureReasons: currentResult.turns
            .flatMap(t => t.judgement.failureReasons || []),
        });
      } else if (baselineResult.status === "failed" && currentResult.status === "passed") {
        improvements.push({
          caseId: currentResult.caseId,
          baselineStatus: "failed",
          currentStatus: "passed",
        });
      }
    }

    // 判断是否可部署
    const canDeploy =
      passRateComparison.diff >= 0 &&  // 通过率不下降
      regressions.length === 0;         // 无回退

    return {
      canDeploy,
      passRateComparison,
      regressions,
      improvements,
      summary: this.generateSummary(canDeploy, passRateComparison, regressions, improvements),
    };
  }
}
```

---

## 五、API 设计

### 5.1 评测集管理

```typescript
// POST /api/eval/datasets/generate
// 从零生成评测集
interface GenerateDatasetRequest {
  targetId: string;
  rolePersonaIds: string[];
  turnsPerCase?: number;
  casesPerRole?: number;
  generatorModel?: ModelConfig;
}

// POST /api/eval/datasets/augment
// 基于种子集二次创作
interface AugmentDatasetRequest {
  seedDatasetId: string;
  strategy: "variation" | "edge_case" | "role_switch" | "difficulty" | "adversarial";
  rolePersonaIds?: string[];     // role_switch 策略时必填
  multiplier?: number;           // 扩展倍数，默认 3
  generatorModel?: ModelConfig;
}

// GET /api/eval/datasets
// 列出评测集

// GET /api/eval/datasets/:id
// 获取评测集详情

// PUT /api/eval/datasets/:id
// 更新评测集（人工修改）

// DELETE /api/eval/datasets/:id
// 删除评测集
```

### 5.2 评测执行

```typescript
// POST /api/eval/runs
// 创建评测运行
interface CreateEvalRunRequest {
  targetId: string;
  datasetIds: string[];
  sceneVersionTag?: string;
  executeModel?: ModelConfig;
  judgeModel?: ModelConfig;
}

// GET /api/eval/runs
// 列出执行记录

// GET /api/eval/runs/:id
// 获取执行详情

// GET /api/eval/runs/:id/results
// 获取执行结果（分页）
```

### 5.3 归因分析

```typescript
// POST /api/eval/runs/:runId/attribution
// 基于评测运行结果的批量归因

// POST /api/eval/attribution/conversation
// 基于单个对话轨迹的归因（支持人工反馈）
interface ConversationAttributionRequest {
  conversation: {
    sessionId: string;
    sceneId: string;
    sceneGroupId?: string;
    turns: {
      turnIndex: number;
      input: string;
      output: string;
      timestamp: string;
      toolCalls?: { name: string; args: Record<string, unknown> }[];
    }[];
  };
  feedback?: {
    scope: "turn" | "conversation";
    turnIndex?: number;
    rating: "positive" | "negative";
    feedbackText?: string;
    selectedReasons?: string[];
    expectedBehavior?: string;
  };
}

// POST /api/eval/attribution/trajectories
// 基于多个对话轨迹的整体优化分析
interface TrajectoryAttributionRequest {
  conversations: ConversationAttributionRequest["conversation"][];
  goal: string;  // 优化目标，如 "提升对话流畅度" "增强引导效果"
}

// GET /api/eval/attributions/:id
// 获取归因结果
```

### 5.4 优化生成

```typescript
// POST /api/eval/runs/:runId/optimize
// 单次优化，生成一个新版本配置

// GET /api/eval/sceneVersions/:sceneId
// 获取场景的版本列表

// GET /api/eval/sceneVersions/:sceneId/:versionTag
// 获取特定版本

// POST /api/eval/sceneVersions/:sceneId/:versionTag/deploy
// 部署版本（覆盖到 sceneList.json）
```

### 5.5 循环优化

```typescript
// POST /api/eval/optimization-loops
// 启动循环优化任务
interface CreateOptimizationLoopRequest {
  targetId: string;              // 评测目标
  datasetIds: string[];          // 使用的评测集
  maxIterations: number;         // 最大循环次数，如 4
  stopOnPassRate?: number;       // 可选：达到该通过率时提前停止，如 0.95
  executeModel?: ModelConfig;    // 执行模型
  judgeModel?: ModelConfig;      // 评判模型
  optimizerModel?: ModelConfig;  // 优化模型（生成新配置用）
}

// GET /api/eval/optimization-loops
// 列出所有循环优化任务

// GET /api/eval/optimization-loops/:loopId
// 获取循环优化任务详情（包含每轮结果）

// POST /api/eval/optimization-loops/:loopId/stop
// 手动停止循环优化

// GET /api/eval/optimization-loops/:loopId/compare
// 对比所有迭代版本，辅助选择最佳版本

// POST /api/eval/optimization-loops/:loopId/select/:versionTag
// 选择某个版本作为正式版并部署
```

### 5.6 劣化检测

```typescript
// POST /api/eval/regression/check
// 劣化检测
interface RegressionCheckRequest {
  baselineRunId: string;
  currentRunId: string;
}
```

### 5.6 定时任务

```typescript
// POST /api/eval/schedules
// 创建定时任务
interface CreateScheduleRequest {
  name: string;
  targetId: string;
  cron: string;              // cron 表达式，如 "0 2 * * *"
  autoOptimize?: boolean;    // 是否自动优化
  notifyOnFailure?: boolean; // 失败时通知
}

// GET /api/eval/schedules
// 列出定时任务

// DELETE /api/eval/schedules/:id
// 删除定时任务
```

---

## 六、文件结构

```
config/
├── eval/
│   ├── rolePersonas.json           # 角色扮演配置
│   ├── failureReasons.json         # 全局失败原因库
│   └── targets/                    # 评测目标
│       ├── edu_simple_modify.json
│       └── devtools_clarification.json
│
├── scenes/
│   ├── sceneList.json              # 场景配置（现有）
│   └── sceneGroupList.json         # 场景组（现有）

data/
└── eval/
    ├── datasets/                   # 评测集
    │   ├── ds_001.json
    │   └── ds_002.json
    │
    ├── runs/                       # 执行记录
    │   ├── run_251127_001.json
    │   └── run_251127_002.json
    │
    ├── loops/                      # 循环优化任务
    │   └── loop_251127_001.json
    │
    └── sceneVersions/              # 场景配置版本
        └── educationSimpleModify/
            ├── educationSimpleModify_opt_251127_01.json
            └── educationSimpleModify_opt_251127_02.json

server/
└── eval/
    ├── generator/
    │   └── datasetGenerator.ts
    ├── executor/
    │   └── evalExecutor.ts
    ├── judge/
    │   └── judgeEngine.ts
    ├── attribution/
    │   └── attributionEngine.ts
    ├── optimization/
    │   └── optimizationEngine.ts
    ├── loop/
    │   └── optimizationLoopEngine.ts
    ├── regression/
    │   └── regressionDetector.ts
    ├── scheduler/
    │   └── evalScheduler.ts
    └── controller/
        └── evalController.ts
```

---

## 七、完整流程示例

### 7.1 单次优化流程

```
1. 触发评测（手动/定时）
   POST /api/eval/runs
   ↓
2. 执行评测
   EvalExecutor.execute()
   - 加载评测集
   - 执行每个 case
   - 收集 actual_output
   - 评判 pass/fail
   ↓
3. 如果通过率 < 100%，触发归因
   POST /api/eval/runs/:runId/attribution
   AttributionEngine.analyze()
   - 聚类失败案例
   - 分析根因
   - 定位配置字段
   ↓
4. 生成优化配置
   POST /api/eval/runs/:runId/optimize
   OptimizationEngine.optimize()
   - 生成新配置
   - 创建新版本
   ↓
5. 用新配置重新评测
   POST /api/eval/runs (with sceneVersionTag)
   ↓
6. 劣化检测
   POST /api/eval/regression/check
   - 对比 baseline vs 新版本
   - 检查是否可部署
   ↓
7. 如果可部署，人工确认后部署
   POST /api/eval/sceneVersions/:sceneId/:versionTag/deploy
```

### 7.2 循环优化流程（推荐）

```
1. 启动循环优化
   POST /api/eval/optimization-loops
   {
     "targetId": "edu_simple_modify",
     "datasetIds": ["ds_001", "ds_002"],
     "maxIterations": 4,           // 最多优化 4 轮
     "stopOnPassRate": 0.95        // 达到 95% 通过率提前停止
   }
   ↓
2. 系统自动执行循环
   ┌────────────────────────────────────────┐
   │  Iteration 1 (baseline)               │
   │  ├─ 评测当前配置 → 通过率 70%          │
   │  ├─ 归因分析 → 发现"语气生硬"问题      │
   │  └─ 生成优化配置 v1                   │
   ├────────────────────────────────────────┤
   │  Iteration 2                          │
   │  ├─ 评测 v1 → 通过率 80% (+10%)       │
   │  ├─ 归因分析 → 发现"引导不足"问题      │
   │  └─ 生成优化配置 v2                   │
   ├────────────────────────────────────────┤
   │  Iteration 3                          │
   │  ├─ 评测 v2 → 通过率 90% (+10%)       │
   │  ├─ 归因分析 → 发现"回复过长"问题      │
   │  └─ 生成优化配置 v3                   │
   ├────────────────────────────────────────┤
   │  Iteration 4                          │
   │  ├─ 评测 v3 → 通过率 95% (+5%)        │
   │  └─ 达到 stopOnPassRate，停止         │
   └────────────────────────────────────────┘
   ↓
3. 查看所有版本对比
   GET /api/eval/optimization-loops/:loopId/compare

   返回：
   ┌──────────┬─────────┬──────────┬──────────┐
   │ 版本     │ 通过率  │ 相比基线 │ 回退数   │
   ├──────────┼─────────┼──────────┼──────────┤
   │ baseline │ 70%     │ -        │ -        │
   │ v1       │ 80%     │ +10%     │ 0        │
   │ v2       │ 90%     │ +20%     │ 1        │  ← 有回退
   │ v3       │ 95%     │ +25%     │ 0        │  ← 推荐
   └──────────┴─────────┴──────────┴──────────┘

   系统推荐：v3（通过率最高且无回退）
   ↓
4. 人工选择版本并部署
   POST /api/eval/optimization-loops/:loopId/select/v3
   - 可以选择系统推荐的版本
   - 也可以选择其他版本（如 v1 更保守）
   - 选择后自动部署到 sceneList.json
```

**循环优化 vs 单次优化**

| 对比项 | 单次优化 | 循环优化 |
|--------|---------|---------|
| 操作次数 | 每轮手动触发 | 一次触发，自动循环 |
| 版本数量 | 1 个 | N 个（可选择最佳） |
| 优化深度 | 单次改进 | 渐进式改进 |
| 人工介入 | 每轮审核 | 最后选择 |
| 适用场景 | 快速修复单个问题 | 系统性优化 |

### 7.3 评测集生成流程

**方式一：从零生成**

```
1. 配置评测目标
   - 选择场景或场景组
   - 设置优化目标
   ↓
2. 选择角色
   - 从 rolePersonas 中选择
   - 或创建自定义角色
   ↓
3. 生成评测集
   POST /api/eval/datasets/generate
   DatasetGenerator.generate()
   - AI 扮演各角色生成对话
   - 生成语义化预期
   ↓
4. 人工审核修改
   PUT /api/eval/datasets/:id
   - 修正不合理的 case
   - 补充边界情况
```

**方式二：基于种子集二次创作**

```
1. 准备种子评测集
   - 人工编写少量高质量 case（如 5-10 条）
   - 或从线上 badcase 中筛选
   ↓
2. 选择扩展策略
   - variation: 生成措辞变体
   - edge_case: 生成边界情况
   - role_switch: 用不同角色改写
   - difficulty: 生成难度梯度
   - adversarial: 生成对抗性输入
   ↓
3. 二次创作
   POST /api/eval/datasets/augment
   DatasetGenerator.augment()
   - 基于每个种子 case 扩展 N 倍
   - 保留与种子的关联关系
   ↓
4. 人工审核修改
   PUT /api/eval/datasets/:id
   - 删除质量差的扩展
   - 调整预期语义
```

**推荐实践**

| 场景 | 推荐方式 |
|------|---------|
| 新场景冷启动 | 从零生成 + 人工审核 |
| 已有少量人工 case | 二次创作（variation + edge_case）|
| 需要测试不同用户群 | 二次创作（role_switch）|
| 优化后回归测试 | 二次创作（adversarial）|

---

## 八、后续扩展

### Phase 2
- 支持 `tools` 字段的优化
- 工具调用序列的评测
- 工具参数正确性检查

### Phase 3
- 线上数据自动入库
- 用户反馈自动处理
- A/B 测试支持

---

## 九、风险与缓解

| 风险 | 缓解措施 |
|------|---------|
| AI 生成的评测集质量不高 | 人工审核机制，支持修改 |
| 优化后配置偏离原意 | 劣化检测，人工确认部署 |
| 评判模型不准确 | 支持配置评判模型，可用更强模型 |
| 循环优化收敛慢 | 设置最大优化轮数，人工介入 |
