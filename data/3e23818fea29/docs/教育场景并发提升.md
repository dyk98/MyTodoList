# 教育场景并发提升
## 背景
● 现有教育主场景依赖 `qwen3-coder-480B-A35B` 等大模型，单请求显存占用 ≈ 激活参数 × 精度 + KV Cache，32 张卡难以支撑高峰期的高频长上下文需求，短期不会新增 GPU，必须通过策略优化提升单位资源的吞吐。
● taiji 资源位仅能提供约 100 QPM 的 32k deepseek31。
## 目标
●并发提升
●成本守恒
●质量/效率守护
●数据化、标准化、可验证、可分析
## 优化方向
将教育 AI 需求划分为「频次 × 资源损耗」四个象限，针对性拆解能力
高资源消耗
↑
┌───────────────┼───────────────┐
│               │               │
│  象限 II      │   象限 I       │
│  低频高耗     │   高频高耗      │
│               │               │
低频 ├───────────────┼───────────────┤ 高频
│               │               │
│  象限 III     │   象限 IV     │
│  低频低耗     │   高频低耗    │
│               │               │
└───────────────┼───────────────┘
↓
低资源消耗


象限	代表场景（示例）	模型策略 	优化重点
Q1 高频/高耗	多 Tool + 长上下文	留在 qwen3-coder/deepseek31，必要时 taiji	拆分场景、限制轮次、Fallback 到摘要 Tool
Q2 高频/低耗	触发次数多，单次轻量，但易被长上下文拖累	小模型直出（Qwen3-4B）或知识检索 + 小模型 或 知识检索	减少上下文继承、控制轮次 ≤3
Q3 低频/高耗	复杂创作等偶发请求	留在 qwen3-coder/deepseek31，必要时 taiji	压缩 Prompt、按需截断历史
Q4 低频/低耗	调研类、告警类	异步/批量执行，小模型优先	批处理+合并响应
## 模型优化
高资源场景请求能力强的大参数模型（qwen3-coder、deepseek31），根据频率的不同可选请求 taiji 或已有显卡部署的模型
低资源场景请求能力相对一般的小参数模型（Qwen3-4B-Instruct-2507）
场景优化
1.上下文优化  
●缩短 system prompt 删除冗余描述，合并重复规则，剔除场景无关文案
●对上下文长度/对话轮数进行限制，超出则开启新对话（比如只支持单轮对话）
示例：删除冗余描述

```
# 优化前（180 tokens）
你是一个专业的客服助手。你需要以专业、友好、耐心的态度回答用户问题。
在回答时，请注意以下几点：
1. 保持专业的语气
2. 确保回答友好
3. 展现耐心的态度
4. 准确理解用户意图
5. 提供清晰的解决方案

# 优化后（80 tokens）
你是客服助手，以专业、友好、耐心的态度回答问题。
要求：准确理解意图、清晰解决方案、简洁表达。
```

2. Tool 精简  
   ●Tool 返回字段按需裁剪（如只回 `analysis/result`），优化 Tool 中的返回信息，尽量避免冗余上下文、无用上下文
   ●只提供必要的 Tool，避免 ToolList 过长影响模型决策
   ●精细化 Tool 能力，比如不返回代码返回使用说明。
3. 场景拆分  
   ●对场景尽可能进行拆分，探索是否还能拆分出低频或低资源场景
## 数据优化
   ● 象限迁移评估：对 Token/上下文 × 调用频率 进行聚合，可量化多少请求因 Prompt 压缩或路由策略从 Q1/Q3 迁移到 Q2/Q4，从而换算 GPU 节省。
   ● Prompt/Tool 压缩收益：对比优化前后的输入输出 tokens、Tool 返回大小，即可得出平均 token 节省率，与 QPS 提升做回归分析，支撑「减少 30% tokens ≈ 并发 +15%」这类论断。
   ● 收敛效率诊断：结合对话轮次、用户/AI 发言次数，识别卡在 5 轮以上的高耗流程，定位需要新增总结 Tool 或快速路径的场景。
   ● 性能瓶颈定位：将响应延迟与 Tool 耗时做联合分析，可判断延迟来自模型、Tool 还是网络，并设置 P95/P99 超阈值的告警与自动回滚。
   ● 质量守护：把满意度、错误率和重试率与象限/模型路由绑定，若某条路由的满意度跌破 4.3，可快速定位到对应 Prompt 或 Tool 策略是否过度压缩。
## 数据上报
### Token 消耗
   | 数据项 | 说明 | 采集频率 |
   |--------|------|----------|
   | 每轮输入 tokens | 每次用户输入的 token 数量 | 每轮 |
   | 每轮输出 tokens | 每次 AI 响应的 token 数量 | 每轮 |
   | System Prompt tokens | System Prompt 的长度 | 每场景 |
   | User Context tokens | 用户上下文历史的长度 | 每轮 |
   | Tool 定义 tokens | Tool 定义的总长度 | 每场景 |
   原因：
   ● 计算资源消耗指数，用于四象限分类
   ● 识别 Prompt 压缩优化空间（如压缩 30% → 提升并发 15%）
   ● 评估上下文增长趋势，优化滑动窗口策略
   ● 计算优化前后的 Token 节省量

### 调用频率
| 数据项 | 说明 | 采集频率 |
|--------|------|----------|
| 场景调用次数 | 每个 scene_id 的调用总数 | 每次会话 |
| 时间分布 | 按小时/天统计的调用量 | 每次会话 |
| QPS 占比 | 该场景占总 QPS 的百分比 | 聚合计算 |
原因：
● 评估四象限分类的"频率"维度
● 识别高频瓶颈场景（优化优先级 P0）
● 规划优化优先级：高频场景优先，低频场景后置
● 验证优化效果：并发能力 = 加权平均优化倍数

### 对话行为
| 数据项 | 说明 | 采集频率 |
|--------|------|----------|
| 每个场景的对话轮次 | 单个场景内的轮次数 | 每场景 |
| 场景切换序列 | 会话中经历的场景顺序 | 每次会话 |
| 用户发言次数 | 用户主动输入的次数 | 每次会话 |
| AI 回复次数 | AI 响应的次数 | 每次会话 |
原因：
● 评估收敛效率（如平均 10 轮 → 优化至 7 轮，节省 30% 资源）
● 发现轮次控制优化机会（强化收敛条件）
● 分析场景拆分的可行性（如 60% 请求 ≤3 轮，适合快速路径）
● 识别用户行为模式

### 响应性能
| 数据项 | 说明 | 采集频率 |
|--------|------|----------|
| 每轮响应延迟 | 单次请求的响应时间 | 每轮 |
| P50/P95/P99 延迟 | 延迟的百分位数 | 聚合计算 |
| 总会话时长 | 从开始到结束的总时间 | 每次会话 |
| 首次响应延迟 | 用户首次输入到首次响应 | 每次会话 |
原因：
● 衡量并发优化效果（如 P95 延迟从 3s → 2s）
● 识别性能瓶颈（如某场景 P99 延迟异常高）
● 设置回滚阈值（如 P95 > 3s 自动回滚）
● 评估批处理的延迟影响

### Tool 使用
| 数据项 | 说明 | 采集频率 |
|--------|------|----------|
| Tool 调用次数 | 每个场景调用 Tool 的总次数 | 每场景 |
| Tool 名称 | 具体调用了哪个 Tool | 每次调用 |
| Tool 执行时间 | Tool 执行的耗时 | 每次调用 |
| Tool 返回数据大小 | 返回结果的字节数/tokens | 每次调用 |
原因：
● 评估 Tool 优化收益（如精简 Tool 返回信息，节省 80% tokens）
● 识别慢 Tool 和冗余调用
● 优化 Tool 定义（如压缩描述，节省 100 tokens/tool）
● 分析 Tool 使用模式，设计更高效的 Tool

### 质量指标
| 数据项 | 说明 | 采集频率 |
|--------|------|----------|
| 用户满意度评分 | 1-5 分评分 | 每次会话（可选） |
| 错误率和错误类型 | 错误分类统计 | 每轮 |
| 是否需要重试 | 用户是否要求重新生成 | 每轮 |
原因：
● 验证优化不降低质量（如满意度保持 4.3+）
● A/B 测试评估（如压缩版 vs 完整版质量对比）
● 建立质量基线，设置回滚阈值
● 识别质量下降的具体原因

