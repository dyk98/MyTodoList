⏺ 今天学到的核心知识点

1. Loss（损失函数）

衡量模型预测与真实值的差距，越小越好。训练的目标就是降低 Loss。

2. 参数（Parameters）

- 神经网络中的权重值（w, b），由训练自动学习
- 数量：百万到万亿级
- 没有预定义含义，功能是训练过程中"涌现"出来的
- 单个参数完全无法理解，整体是黑盒

3. 调整参数 = 梯度下降

计算 Loss → 反向传播算梯度 → 更新参数
新参数 = 旧参数 - 学习率 × 梯度
自动重复数百万次，让模型越来越准确。

4. 增加参数 = 增强能力

- 方法：增加层数、增加每层神经元数
- 理论上可以任意加，实际受限于算力、数据、成本
- GPT-3: 1750亿参数，训练成本数千万美元

5. 超参数（Hyperparameters）

人类手动设置的训练配置，训练前就固定：
- learning_rate: 参数调整的步长
- batch_size: 每次训练用多少样本
- epochs: 训练多少轮
- hidden_size: 每层多少神经元

6. 推理超参数（采样参数）

控制模型生成文本的方式：
- temperature: 控制随机性（0=确定，2=疯狂）
- top_p: 从累积概率前 p% 的词中选（常用 0.9）
- top_k: 从概率最高的 k 个词中选

代码生成 → temperature=0（要确定性）
创意写作 → temperature=1.2（要多样性）

7. 奖励函数（Reward Function）

强化学习中评价输出好坏的打分系统：
- 好输出 → 高分 → 增加概率
- 坏输出 → 低分 → 降低概率

ChatGPT 的 RLHF 训练：
1. 预训练（学语言）
2. 监督微调（学对话）
3. RLHF（用奖励函数优化成"有用、安全、诚实"）

  ---
关键对比

| 概念    | 谁设置  | 数量     | 例子                  |
  |-------|------|--------|---------------------|
| 参数    | 自动学习 | 数十亿    | w=0.00347           |
| 训练超参数 | 人类设置 | 10-50个 | learning_rate=0.001 |
| 推理超参数 | 用户设置 | 3-5个   | temperature=0.7     |
| 奖励函数  | 人类设计 | 1个     | 有用+10分，有害-100分      |

  ---
核心理解

神经网络 = 黑盒系统
- 通过海量参数自动学习
- 人类只能设置目标（Loss、Reward），无法精确控制内部逻辑
- 参数越多 → 能力越强 → 成本越高 → 越难理解