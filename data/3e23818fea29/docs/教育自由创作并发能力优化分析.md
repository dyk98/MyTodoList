# 教育自由创作并发能力优化分析

> 场景拆分数据来源：[对话分析报告](./对话分析报告.md)（173 条真实用户对话样本）

## 背景

原有自由创作场景存在高频高耗问题，单次请求平均耗时 2 分钟，严重限制了系统并发能力。通过场景拆分和模型替换两项优化措施，显著提升了系统吞吐量。

## 优化前状态

| 指标                      | 数值         |
|-------------------------|------------|
| 模型                      | qwen3coder |
| TPM (Tokens Per Minute) | 12,000     |
| 单次请求平均耗时                | 2 分钟       |
| 场景类型                    | 高频高耗（未拆分）  |

### 原始并发能力分析

- 单次请求占用时间：2 分钟
- 每分钟可处理请求数：约 0.5 次
- 并发瓶颈：长耗时请求持续占用 TPM 配额

## 优化措施

### 优化一：场景拆分

基于真实用户对话数据分析（173 条样本），将场景拆分为两类：

| 场景类型        | 优化前耗时 | 优化后耗时 | 占比    |
|-------------|-------|-------|-------|
| 简单需求        | 2 分钟  | 30 秒  | 91.3% |
| 大型工作（完整小程序） | 2 分钟  | 3 分钟* | 8.7%  |

> *大型工作允许更充分的处理时间以提升生成质量

**整体时间效率提升**：2.79 倍（详见下方计算）

### 优化二：模型替换

| 指标  | 优化前        | 优化后        |
|-----|------------|------------|
| 模型  | qwen3coder | MiniMax-M2 |
| 参数量 | 480B       | 230B       |
| TPM | 12,000     | 13,500     |

**TPM 优化比**：13,500 / 12,000 = **1.125 倍提升**

### 优化三：实例扩容（资源不变）

由于模型参数量从 480B 降至 230B，在相同计算资源下可部署更多推理实例：

```
实例扩容比 = 原参数量 / 新参数量
          = 480B / 230B
          ≈ 2.09 倍
```

**实例扩容提升**：相同资源可部署约 **2.09 倍** 实例数

## 综合效果计算

### 场景拆分效率计算

基于 173 条真实对话样本：

```
优化前总时间 = 173 × 2 min = 346 min
优化后总时间 = 15 × 3 min + 158 × 0.5 min = 45 + 79 = 124 min

场景拆分提升 = 346 / 124 ≈ 2.79 倍
```

### 综合提升倍数

```
综合提升倍数 = 场景拆分提升 × TPM 提升 × 实例扩容提升
            = 2.79 × 1.125 × 2.09
            ≈ 6.56 倍
```

### 详细对比

| 指标              | 优化前    | 优化后    | 提升倍数      |
|-----------------|--------|--------|-----------|
| 平均单次耗时          | 120 秒  | 43 秒   | 2.79×     |
| TPM 限制          | 12,000 | 13,500 | 1.125×    |
| 可部署实例数          | 1×     | 2.09×  | 2.09×     |
| **系统总吞吐量**      | 基准     | -      | **~6.5×** |
| 简单需求等待时间（91.3%） | 2 分钟   | 30 秒   | 减少 75%    |

### 按场景类型分析

场景调用分布（基于真实数据）：

- 简单需求占比：91.3%（158 条）
- 大型工作占比：8.7%（15 条）

**简单需求场景提升**（受场景优化 + TPM + 实例扩容影响）：

```
简单需求提升 = (2min/0.5min) × 1.125 × 2.09
            = 4 × 1.125 × 2.09
            ≈ 9.4 倍
```

**大型工作场景提升**（仅受 TPM + 实例扩容影响，耗时反增）：

```
大型工作提升 = (2min/3min) × 1.125 × 2.09
            = 0.67 × 1.125 × 2.09
            ≈ 1.57 倍
```

**加权平均提升**：

```
整体提升 = 0.913 × 9.4 + 0.087 × 1.57
        = 8.58 + 0.14
        ≈ 6.5 倍（与综合提升计算一致）
```

## 总结

| 优化项                   | 提升效果        |
|-----------------------|-------------|
| 场景拆分（基于 173 条真实数据）    | 2.79 倍      |
| 模型替换（TPM 提升）          | 1.125 倍     |
| 实例扩容（参数量 480B→230B）   | 2.09 倍      |
| **简单需求场景综合提升**（91.3%） | **9.4 倍**   |
| **系统整体提升（加权）**        | **约 6.5 倍** |

### 关键收益

1. **用户体验提升**：91.3% 的简单需求响应时间从 2 分钟降至 30 秒，减少 75%
2. **系统吞吐量提升**：相同资源下可服务用户数提升约 6.5 倍
3. **质量与效率平衡**：大型工作（8.7%）允许 3 分钟充分处理，提升生成质量
4. **资源利用率优化**：小参数模型（230B vs 480B）可部署 2 倍实例，同时获得更高 TPM 配额
5. **弹性扩展能力**：短请求更易于负载均衡和故障恢复

---

## 相关文档

- [对话分析报告](./对话分析报告.md) - 场景拆分数据来源（173 条真实用户对话）
- [MiniMax M2 压测报告](./minimax-m2-stress-2025-12-04T07-14-57-129Z.md) - 模型实际性能验证
