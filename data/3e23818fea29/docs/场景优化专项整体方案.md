# 场景优化专项整体方案

## 一、背景

我们有两个独立但相关的优化方向：

1. **场景配置自优化**：通过评测、归因、自动生成新配置来提升 AI 对话质量
2. **教育场景并发提升**：通过四象限分类、模型路由、Prompt 压缩来提升系统性能

两者优化的是不同的"层"，但存在共同点：
- 都需要数据驱动
- 都需要闭环验证
- 都可能相互影响（性能优化可能影响质量，质量优化可能影响性能）

**核心问题**：能否将两者整合成一个统一的优化框架？

---

## 二、整合思路

### 2.1 核心洞察

两个系统可以共享同一套数据基础设施和闭环机制，但保持独立的触发和执行逻辑。

```
输入独立 → 分析统一 → 执行独立
```

### 2.2 两个数据源

| 数据源 | 来源 | 驱动的优化 |
|--------|------|-----------|
| 用户输入 | 点赞/踩、对话反馈、评测结果 | 质量优化（配置层） |
| 数据输入 | Token 消耗、延迟、调用频率 | 性能优化（资源层） |

### 2.3 设计原则

1. **数据层统一**：一次采集，多处使用
2. **子系统独立**：各自触发、各自执行、各自验证
3. **关键节点人工决策**：质量与性能冲突时人工介入
4. **渐进式融合**：先独立验证价值，再考虑深度整合

---

## 三、整体架构

```
┌─────────────────────────────────────────────────────────────┐
│              场景优化专项 - 整体架构                          │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────────────────────────────────────────────────┐    │
│  │                 统一数据层 (Day 1 建设)              │    │
│  │  · 统一数据模型                                      │    │
│  │  · 统一采集 SDK                                      │    │
│  │  · 统一存储                                          │    │
│  └─────────────────────────────────────────────────────┘    │
│                            │                                │
│              ┌─────────────┴─────────────┐                  │
│              ▼                           ▼                  │
│  ┌─────────────────────┐    ┌─────────────────────┐        │
│  │   质量优化子系统     │    │   性能优化子系统     │        │
│  │                     │    │                     │        │
│  │ · 评测集管理        │    │ · 四象限分类        │        │
│  │ · 自动归因          │    │ · 路由策略          │        │
│  │ · 配置优化          │    │ · Prompt 压缩       │        │
│  │ · 劣化检测          │    │ · 性能监控          │        │
│  └──────────┬──────────┘    └──────────┬──────────┘        │
│             │                          │                    │
│             └────────────┬─────────────┘                    │
│                          ▼                                  │
│  ┌─────────────────────────────────────────────────────┐    │
│  │              协调层 (Phase 2 建设)                   │    │
│  │  · 冲突检测                                          │    │
│  │  · 人工决策点                                        │    │
│  │  · 联合归因                                          │    │
│  └─────────────────────────────────────────────────────┘    │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

## 四、统一数据层设计

### 4.1 数据模型

```
会话 (Session)
├── session_id
├── scene_id
├── user_id
├── created_at
│
├── 质量维度
│   ├── user_feedback (点赞/踩/原因)
│   ├── eval_result (评测通过/失败)
│   └── badcase_reason (失败原因分类)
│
├── 性能维度
│   ├── input_tokens / output_tokens
│   ├── system_prompt_tokens
│   ├── response_latency
│   ├── model_used
│   └── quadrant (Q1/Q2/Q3/Q4)
│
└── 行为维度
    ├── dialogue_rounds
    ├── tool_calls []
    │   ├── tool_name
    │   ├── execution_time
    │   └── return_size
    └── scene_switches []
```

### 4.2 统一数据层的价值

| 价值 | 说明 |
|------|------|
| 关联分析 | 发现"压缩 Prompt 后质量下降的 case 集中在哪类场景" |
| 根因定位 | 延迟高是因为模型慢、Tool 慢、还是轮次多 |
| 效果验证 | 同一份数据验证质量和性能两个维度的变化 |
| 避免重复建设 | 一次采集，多处使用 |

### 4.3 采集清单

#### Token 消耗
| 数据项 | 说明 | 采集频率 |
|--------|------|----------|
| 每轮输入 tokens | 每次用户输入的 token 数量 | 每轮 |
| 每轮输出 tokens | 每次 AI 响应的 token 数量 | 每轮 |
| System Prompt tokens | System Prompt 的长度 | 每场景 |
| User Context tokens | 用户上下文历史的长度 | 每轮 |
| Tool 定义 tokens | Tool 定义的总长度 | 每场景 |

#### 调用频率
| 数据项 | 说明 | 采集频率 |
|--------|------|----------|
| 场景调用次数 | 每个 scene_id 的调用总数 | 每次会话 |
| 时间分布 | 按小时/天统计的调用量 | 每次会话 |
| QPS 占比 | 该场景占总 QPS 的百分比 | 聚合计算 |

#### 对话行为
| 数据项 | 说明 | 采集频率 |
|--------|------|----------|
| 每个场景的对话轮次 | 单个场景内的轮次数 | 每场景 |
| 场景切换序列 | 会话中经历的场景顺序 | 每次会话 |
| 用户发言次数 | 用户主动输入的次数 | 每次会话 |
| AI 回复次数 | AI 响应的次数 | 每次会话 |

#### 响应性能
| 数据项 | 说明 | 采集频率 |
|--------|------|----------|
| 每轮响应延迟 | 单次请求的响应时间 | 每轮 |
| P50/P95/P99 延迟 | 延迟的百分位数 | 聚合计算 |
| 总会话时长 | 从开始到结束的总时间 | 每次会话 |
| 首次响应延迟 | 用户首次输入到首次响应 | 每次会话 |

#### Tool 使用
| 数据项 | 说明 | 采集频率 |
|--------|------|----------|
| Tool 调用次数 | 每个场景调用 Tool 的总次数 | 每场景 |
| Tool 名称 | 具体调用了哪个 Tool | 每次调用 |
| Tool 执行时间 | Tool 执行的耗时 | 每次调用 |
| Tool 返回数据大小 | 返回结果的字节数/tokens | 每次调用 |

#### 质量指标
| 数据项 | 说明 | 采集频率 |
|--------|------|----------|
| 用户满意度评分 | 1-5 分评分 | 每次会话（可选） |
| 错误率和错误类型 | 错误分类统计 | 每轮 |
| 是否需要重试 | 用户是否要求重新生成 | 每轮 |
| 评测通过/失败 | 自动评测结果 | 每次评测 |
| 失败原因分类 | badcase 的具体原因 | 每次评测 |

---

## 五、质量优化子系统

### 5.1 核心闭环

```
自提问 → 自执行 → 自归因 → 自优化
   ↑                          ↓
   └──────── 循环 ─────────────┘
```

### 5.2 核心能力

| 能力 | 说明 |
|------|------|
| 评测集管理 | AI 生成 + 种子扩展 + 人工编辑 |
| 自动评测 | 批量执行评测集，收集结果 |
| 归因分析 | 分析失败原因，定位到配置字段 |
| 配置优化 | 自动生成新配置版本 |
| 循环优化 | 多轮迭代直到达到目标 |
| 劣化检测 | 确保优化不引入新问题 |

### 5.3 触发条件

- 用户反馈（点踩）
- 评测通过率下降
- 定期巡检发现问题
- 人工主动触发

---

## 六、性能优化子系统

### 6.1 四象限分类

```
高资源消耗
     ↑
┌────────────┼────────────┐
│            │            │
│  象限 II   │  象限 I    │
│  低频高耗  │  高频高耗  │
│            │            │
低频 ────────┼──────────── 高频
│            │            │
│  象限 III  │  象限 IV   │
│  低频低耗  │  高频低耗  │
│            │            │
└────────────┼────────────┘
     ↓
低资源消耗
```

### 6.2 优化策略

| 象限 | 代表场景 | 模型策略 | 优化重点 |
|------|---------|---------|---------|
| Q1 高频/高耗 | 多 Tool + 长上下文 | 大模型 | 拆分场景、限制轮次、Fallback |
| Q2 高频/低耗 | 触发多、单次轻量 | 小模型 | 减少上下文、控制轮次 ≤3 |
| Q3 低频/高耗 | 复杂创作 | 大模型 | 压缩 Prompt、按需截断 |
| Q4 低频/低耗 | 调研类 | 小模型 | 批处理 + 合并响应 |

### 6.3 触发条件

- QPS 超过阈值
- P95 延迟超标
- 成本预算告警
- 定期策略评估

---

## 七、协调层设计

### 7.1 冲突场景

质量优化和性能优化可能存在冲突：

| 质量优化建议 | 性能优化建议 | 冲突 |
|-------------|-------------|------|
| 增加 Prompt 描述以提升准确性 | 压缩 Prompt 以节省 Token | 冲突 |
| 增加对话轮次以充分引导 | 限制轮次以提升并发 | 冲突 |
| 使用大模型保证质量 | 路由到小模型降低成本 | 冲突 |

### 7.2 人工决策点

```
┌─────────┐    自动    ┌─────────┐
│ 性能优化 │ ─────────▶│ 质量检测 │
│ 建议压缩 │           │ 发现下降 │
└─────────┘           └────┬────┘
                           │
                           ▼ 触发人工决策
                    ┌─────────────┐
                    │  决策面板    │
                    │             │
                    │ 选项A: 接受压缩，质量可接受  │
                    │ 选项B: 放弃压缩，保质量优先  │
                    │ 选项C: 折中方案（AI 生成）   │
                    └─────────────┘
```

### 7.3 自动决策阈值

不是所有冲突都需要人工介入：

| 场景 | 阈值 | 处理方式 |
|------|------|---------|
| 质量下降 < 5% | 可接受 | 自动接受性能优化 |
| 质量下降 5%-10% | 需关注 | 触发人工决策 |
| 质量下降 > 10% | 不可接受 | 自动拒绝性能优化 |

---

## 八、实施计划

### Phase 1a：统一数据层

**目标**：建设数据基础设施

**产出**：
- 统一数据模型定义
- 采集 SDK
- 数据存储方案
- 基础看板

### Phase 1b：质量优化子系统

**目标**：独立跑通质量优化闭环

**产出**：
- 评测集管理能力
- 自动归因能力
- 配置优化能力
- 劣化检测能力

### Phase 1c：性能优化子系统

**目标**：独立跑通性能优化闭环

**产出**：
- 四象限自动分类
- 路由策略引擎
- Prompt 压缩工具
- 性能监控看板

### Phase 2：协调层

**目标**：实现两个子系统的协调

**产出**：
- 冲突检测机制
- 人工决策面板
- 联合效果验证

### Phase 3：深度融合

**目标**：实现智能协调

**产出**：
- 联合归因（质量问题 vs 性能优化导致）
- 智能决策（自动平衡质量和性能）
- 全局最优策略推荐

---

## 九、预期收益

### 效率提升

| 指标 | 现状 | 目标 |
|------|------|------|
| 单场景优化周期 | 1-2 周 | 1-2 天 |
| 问题发现时间 | 用户反馈后 | 主动发现 |
| 性能调优周期 | 人工分析 | 数据驱动 |

### 质量保障

- 每次优化都有评测验证
- 劣化检测确保不引入新问题
- 质量与性能双重守护

### 成本优化

- 四象限分类实现精细化资源调度
- Prompt 压缩降低 Token 消耗
- 模型路由降低大模型使用比例

---

## 十、总结

这个方案的核心理念是：

> **数据统一是基础，子系统独立是务实，协调层是未来**

通过统一的数据层，我们可以同时支撑质量优化和性能优化两个子系统，让它们各自独立运行、独立验证价值。在关键冲突点引入人工决策，确保在追求效率的同时不牺牲质量。

最终目标是实现：
- **用户反馈** 能快速转化为质量提升
- **性能数据** 能自动驱动资源优化
- **两者协调** 在人工把关下达到全局最优
